# NLP

#NLP Embeddings

Introduction to NLP and Work Embeddings

**********

#BERT from Scratch

Problem Scenario: 

In this assignment, you are tasked with developing your own minimalist version of the BERT (Bidirectional Encoder Representations from Transformers) model. BERT is a state-of-the-art language model that utilizes transformer-based architectures for various natural language processing tasks.

Your objective is to implement some key components of the BERT model to gain a deeper understanding of its architecture. You will focus on developing the necessary modules and functionalities required for sentence classification using BERT.

The assignment will involve performing sentence classification on two datasets: the sst dataset and the cfimdb dataset. These datasets contain labeled sentences, and your goal is to train your BERT model to classify the sentences into appropriate categories based on their semantic meanings.

Important Details and Notes:

1) Ensure that you follow the provided setup.sh script to set up the environment and install the required dependencies. It is crucial to work within the designated environment for consistency.
2) Refer to the structure.md document for a detailed description of the code structure, including the specific components you need to implement.
3) You are only allowed to use the torch library for this assignment. Other external libraries, such as transformers, are not permitted.
4) The code you submit should be reproducible using the provided commands. 

Task:

Your task is to carefully implement the necessary components of the BERT model, perform sentence classification on the sst and cfimdb datasets, and aim for the best possible performance. Through this assignment, you will gain practical experience in building and training a BERT-based model for sentence classification tasks.

*************

# Sentence Classification from Scratch
